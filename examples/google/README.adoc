= StudioML distributed evaluation and model serving
ifdef::env-github[]
:imagesdir:
https://raw.githubusercontent.com/leaf-ai/studio-go-runner/main/docs/artwork
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:imagesdir: ./
endif::[]

:toc:
:toc-placement!:

This document details a Google Cloud deployment of a standalone StudioML Go Runner (runner) compute cluster.

This document is aimed at an audience with Google Cloud skills and sufficent account rights for full account management.

toc::[]

== Setup

:source-highlighter: coderay

Prerequistes prior to using google installation tooling include installations of the kubectl Kubernetes CLI tool, https://kubernetes.io/docs/tasks/tools/install-kubectl/, and the Kubernernetes SIG Kustomize tool, https://kubectl.docs.kubernetes.io/installation/kustomize/.

[source,shell]
----
$ snap install google-cloud-sdk --classic
$ gcloud init
Welcome! This command will take you through the configuration of gcloud.

Your current configuration has been set to: [default]

You can skip diagnostics next time by using the following flag:
  gcloud init --skip-diagnostics

Network diagnostic detects and fixes local network connection issues.
Checking network connection...done.
Reachability Check passed.
Network diagnostic passed (1/1 checks passed).

You must log in to continue. Would you like to log in (Y/n)?  y

Go to the following link in your browser:

    https://accounts.google.com/o/oauth2/auth?redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&prompt=select_account&response_type=code&client_id=999999999.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&access_type=offline


Enter verification code: 347dHJG^#234/&T&WSHid237


To take a quick anonymous survey, run:
  $ gcloud alpha survey

You are logged in as: [karl.mutch@cognizant.com].

Pick cloud project to use:
 [1] cdb-aia-leaf1000999999
 [2] Create a new project
Please enter numeric choice or text value (must exactly match list
item):  1

Your current project has been set to: [cdb-aia-leaf1000999999].

Not setting default zone/region (this feature makes it easier to use
[gcloud compute] by setting an appropriate default value for the
--zone and --region flag).
See https://cloud.google.com/compute/docs/gcloud-compute section on how to set
default compute region and zone manually. If you would like [gcloud init] to be
able to do this for you the next time you run it, make sure the
Compute Engine API is enabled for your project on the
https://console.developers.google.com/apis page.

Created a default .boto configuration file at [/home/kmutch/.boto]. See this file and
[https://cloud.google.com/storage/docs/gsutil/commands/config] for more
information about configuring Google Cloud Storage.
Your Google Cloud SDK is configured and ready to use!

* Commands that require authentication will use karl.mutch@cognizant.com by default
* Commands will reference project `cdb-aia-leaf1000999999` by default
Run `gcloud help config` to learn how to change individual settings

This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.
Run `gcloud topic configurations` to learn more.

Some things to try next:

* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.
* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting
----

For more information please see, https://cloud.google.com/sdk/docs/downloads-snap.

== RabbitMQ on Google Cloud

The RabbitMQ component of a runner deployment is typically a stable component that can be deployed using a Virtual Machine outside of a Kubernetes cluster.  The easiest way to deploy this component is via the Google Marketplace distribution of the bitnami packaged RabbitMQ non clustered version and the Google click to deploy option.

When creating the VM a base configuration should start with the n1-standard-2 configuration, and a 20GB Standard Disk.

Choose a zone for the VM that fits your requirements for other compute resource availability, for example a zone that can host your GPU based instances for StudioML.

For more information please review the https://github.com/GoogleCloudPlatform/click-to-deploy/blob/master/k8s/rabbitmq/README.md#installation[Bitnami RabbitMQ Installation README].

After deployment the Cloud Console Deployment Manager can be used to access your deployment and will show a temporary admin password and IP address for the machine.  The deployment page can be used to create an SSH session to the machine, once logged in the default admin password can be changed using the following command:

[source, shell]
----
sudo rabbitmqctl change_password admin NEW_PASSWORD
----
 
The SSH shell can also be used to add user accounts for the experimenters wishing to queue work to your compute cluster.  Bitnami packaging for services is similar across cloud providers so the commands should be the same across providers for SSH based administration, for more information about adding users etc please see, https://docs.bitnami.com/bch/infrastructure/rabbitmq/administration/[Bitnami RabbitMQ Administration].

If you intend on accessing the RabbitMQ server externally then you will need to assign an external IP address for the machine using the instructions posted at, https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address?hl=en_US#promote_ephemeral_ip[Promoting an ephemeral external IP address].

In addition the firewall for the VM network interface should be configured to allow for ports 5672, and 15672 to be permitted for inbound connections.

Having configured RabbitMQ you should updated any StudioML configuration file being used with the new external IP address, username, and password as follows:

.~/.studioml/config.yaml
[source,yaml]
----
cloud:
    queue: 
        rmq: "amqp://[username]:[password]@[external IP address]:5672/%2f?connection_attempts=30&retry_delay=.5&socket_timeout=5"

server:
    authentication: None

----


Any changes to the yaml format of studioml should be translatable into json or hocon formats used by the completion service, although you should check the LEAF ENN SDK and API documentation for further details.

In the event that you remain with a Google account level IP address this should be used for the configuration.

Our next step is to modify the deployment.yaml file and the config map studioml-env that will be used by the runners to include this configuration for the RabbitMQ.

.deployment.yaml
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
 name: studioml-env
data:
  AMQP_URL: "amqp://[username]:[password]@[external IP address]:5672/%2f?connection_attempts=30&retry_delay=.5&socket_timeout=5"
...
----

===Google Cloud Storage

The next step is to create a storage bucket for experiment metadata, and training data and results.  The Console web UI can be used for this, be sure to 
choose a region for storage that matches the same region as you intend to locate the compute cluster within.  In most cases a Region level bucket for a single region is initially a good place to start.

Bucket access policies are often the most easily managed, having the same access policy for all objects in a bucket.  This means that for multiple departments there should be multiple buckets.  This leads to fewer issues when managing access as it will be uniform across an entire bucket.

Once the buckets are created you should modify the database and storage sections of the StudioML configuration as follows:

.~/.studioml/config.yaml
[source,yaml]
----
database:
     type: s3
     endpoint: https://storage.googleapis.com
     bucket: leaf-metadata
     authentication: none

storage:
     type: s3
     endpoint: https://storage.googleapis.com
     bucket: leaf-store

----

You should now use the Google Cloud Storage -> Settings page to add access keys to the user accounts that will need to access these buckets.  These can be generated in the same web UI page.  The key and secret generated can then be used as environment variables for AWS_ACCESS_KEY_ID, and AWS_SECRET_ACCESS_KEY respectively.

If you are using the minio client to access these buckets from a local Linux account then the following commands will enabled you to access and use the bucket.

[source,shell]
----
$ mc config host add gcs https://storage.googleapis.com GOOGSAccessKey +long/confusing-looking-secret --api S3v2
Added `gcs` successfully.
$ mc ls leaf-metadata
----

In addition to being set as the standard AWS_ environment variables these secrets should be injected into the StudioML configuration file:

.~/.studioml/config/yaml
[source,yaml]
----
env:
    AWS_ACCESS_KEY_ID: GOOGSAccessKey
    AWS_SECRET_ACCESS_KEY: +long/confusing-looking-secret
    AWS_DEFAULT_REGION: us-west1
----

=== Studio Go Runner

The runner is typically deployed in a cluster scenario with multiple Kubernetes nodes provisioned with GPUs.  For GCP the recommendation is to make use of the cloud console for cluster creation and management.

Some things to note when using the console UI :

* The console UI allows you to generate the equivalent CLI command, or REST body, to create a cluster to help with scripting and automation
* Locate you cluster within the same region/zone as your data buckets were created
* The cluster will require several nodes to start the basic Kubernetes and OpenStack pods which google uses.  In order to prevent these pods running on valuable GPU enabled nodes two node pools should be created.  The node pool for the Kubernetes management pods can be addressed using  one that has e2-standard-4 nodes configured with auto-scaling enabled with a maximum of 3 nodes running the container optimized operating system image.
* A GPU enabled node pool should be created for the runner deployment with as many nodes as needed for any experiments that are to be run.
* Cloud platforms have restrictions on the numbers of pods per node, and the number of nodes that can be allocated due to IP address range sizes, please read https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr[POD CIDR flexibility], and https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr#creating_a_cluster_with_a_maximum_of_110_pods_per_node[Using VPC-Native clusters with GCP].  Do not ignore this as experiments can scale to large sizes especially if workloads are elastic.
* Elastic node allocation, an as yet rarely used feature, requires specialized runner features, please contact the authors for more information.
* When specifing the node type for the GPU node pool you will need to ensure that the GPUs required are available within the zone used by your buckets.  For information please review https://cloud.google.com/compute/docs/gpus#gpu-virtual-workstations[GPU Virtual Workstations].  Also be sure to choose a general purpose GPU rather than an inferencing specific offering. A good GPU pool node type to start with is the N1 series, n1-standard-4.
* When creating the GPU node pool the GPU enabled nodes will add a taint to preveent non GPU workloads from, being scheduled.  The taint is 'nvidia.com/gpu=present'.

[source,shell]
----
$ export KUBECONFIG=~/.kube/gcp-cluster-1
$ gcloud container clusters get-credentials cluster-1 --zone us-west1-b
Fetching cluster endpoint and auth data.
kubeconfig entry generated for cluster-1.
----

More information can be found at, https://cloud.google.com/sdk/gcloud/reference/container/clusters/get-credentials[get-credentials].

Once the credentials are loaded you will be able to query for a list of the nodes across all pools as follows:

[source,shell]
----
$ kubectl get nodes
NAME                                            STATUS   ROLES    AGE   VERSION
gke-cluster-1-gpu-pool-1-d15e5c28-7h23          Ready    <none>   10m   v1.17.13-gke.2600
gke-cluster-1-management-pool-1-998a7d88-4bl2   Ready    <none>   62m   v1.17.13-gke.2600
gke-cluster-1-management-pool-1-998a7d88-hxcw   Ready    <none>   64m   v1.17.13-gke.2600
gke-cluster-1-management-pool-1-998a7d88-kxpr   Ready    <none>   62m   v1.17.13-gke.2600
----

The driver must be loaded manually into the deployment to populate the Nvidia GPU driver on to the Kubernetes hosts.

[source,shell]
----
$ kubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/container-engine-accelerators/master/nvidia-driver-installer/cos/daemonset-preloaded.yaml
----


If the daemonset loads corectly you will see that your GPU node has an availble allocate resource :

----
$ kubectl describe node gke-cluster-1-gpu-pool-1-d15e5c28-7h23
...
Allocatable:
  attachable-volumes-gce-pd:  127
  cpu:                        3920m
  ephemeral-storage:          47093746742
  hugepages-2Mi:              0
  memory:                     12698360Ki
  nvidia.com/gpu:             1
  pods:                       8
...
----

More information can be found at https://cloud.google.com/kubernetes-engine/docs/how-to/gpus#installing_drivers[How to Load GPU Drivers].

Prior to applying the deployment the StudioML installation will require several secrets to be loaded related to encryption.  Even if encryption wont be used the secrets for the cluster owner will need to be deployed.  The instructions for this can be found at https://github.com/leaf-ai/studio-go-runner/blob/main/docs/message_privacy.md#request-encryption[Request Encryption].

If you wish to use local SSH keys within a user specific cluster the following commands can be used.

.Generating a new password protected encryption key
[source,shell]
----
echo -n "PassPhrase" > secret_phrase
ssh-keygen -t rsa -b 4096 -f studioml_request -C "Message Encryption Key" -N "PassPhrase"
ssh-keygen -f studioml_request.pub -e -m PEM > studioml_request.pub.pem
cp studioml_request studioml_request.pem
ssh-keygen -f studioml_request.pem -e -m PEM -p -P "PassPhrase" -N "PassPhrase"
----

.Using your existing keys to add secrets
[source,shell]
----
kubectl create secret generic studioml-runner-key-secret --from-file=ssh-privatekey=studioml_request.pem --from-file=ssh-publickey=studioml_request.pub.pem
kubectl create secret generic studioml-runner-passphrase-secret --from-file=ssh-passphrase=secret_phrase
----


After populating secrets our next step is to perform the actual deployment using the following command:

[source,shell]
----
$ kubectl apply -f deployment.yaml
----

After which the pod in our test cluster can be seen and we can extract the console logs as follows:


[source,shell]
----
$ kubectl get pods
NAME                                            READY   STATUS    RESTARTS   AGE
studioml-go-runner-deployment-d4499bb9f-2jg82   1/1     Running   0          9m
$ kubectl logs -f | tail
2020-11-23T22:58:16+0000 WRN runner no queues found _: [[identity amqp://35.236.125.208:5672/%2f matcher ^rmq_.*$ stack [rabbit.go:202]] host studioml-go-runner-deployment-d4499bb9f-2jg82] in:
2020-11-23T22:58:46+0000 WRN runner no queues found _: [[identity amqp://35.236.125.208:5672/%2f matcher ^rmq_.*$ stack [rabbit.go:202]] host studioml-go-runner-deployment-d4499bb9f-2jg82] in:
2020-11-23T22:59:16+0000 WRN runner no queues found _: [[identity amqp://35.236.125.208:5672/%2f matcher ^rmq_.*$ stack [rabbit.go:202]] host studioml-go-runner-deployment-d4499bb9f-2jg82] in:
----

This shows that the runner can successfully read queues for work and now we can use studioml to run a very simple test job from the studioml python client.
s we have to prepare the ~/.studioml/config as detailed in the previous sections.

The next step is to load your StudioML python client environment using a Python Virtual Environment.  The Kera example can be run by using the following commands:

[source,shell]
----
$ cd examples/keras
$ studio run --lifetime=30m --max-duration=20m --gpus 2 --queue=rmq_test --force-git train_mnist_keras.py
...
2020-11-24 10:47:22 DEBUG  studio-runner - sent message to amqp://user:NEW_PASSWORD@35.236.125.208:5672/%2f?connection_attempts=30&retry_delay=.5&socket_timeout=5
2020-11-24 10:47:22 DEBUG  studio-runner - received ack for delivery tag: 1
2020-11-24 10:47:22 INFO   studio-runner - published 1 messages, 0 have yet to be confirmed, 1 were acked and 0 were nacked
2020-11-24 10:47:23 INFO   studio-runner - sent message acknowledged to amqp://user:NEW_PASSWORD@35.236.125.208:5672/%2f?connection_attempts=30&retry_delay=.5&socket_timeout=5 after waiting 1 seconds
2020-11-24 10:47:23 INFO   studio-runner - studio run: submitted experiment 1606243639_de40c8d0-6e47-4df9-be5a-0f67ecb9ad6b
2020-11-24 10:47:23 INFO   studio-runner - Added 1 experiment(s) in 3 seconds to queue rmq_kmutch
----

The experiment results can be seen using the minio client previously defined endpoint:

[source,shell]
----
$ mc ls gcs/leaf-store/experiments/1606243639_de40c8d0-6e47-4df9-be5a-0f67ecb9ad6b/output.tar
[2020-11-24 10:50:13 PST]  148KiB output.tar
$ mc cp gcs/leaf-store/experiments/1606243639_de40c8d0-6e47-4df9-be5a-0f67ecb9ad6b/output.tar ./output.tar
...5a-0f67ecb9ad6b/output.tar:  148.50 KiB / 148.50 KiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 224.82 KiB/s 0
$ tar xf output.tar
$ tail output -n 140 | head -n 20
Epoch 6/10
60000/60000 [==============================] - 2s - loss: 0.2976 - acc: 0.9151 - val_loss: 0.2809 - val_acc: 0.9205
Epoch 7/10
60000/60000 [==============================] - 1s - loss: 0.2810 - acc: 0.9196 - val_loss: 0.2651 - val_acc: 0.9240
Epoch 8/10
60000/60000 [==============================] - 1s - loss: 0.2669 - acc: 0.9236 - val_loss: 0.2555 - val_acc: 0.9260
Epoch 9/10
60000/60000 [==============================] - 1s - loss: 0.2545 - acc: 0.9278 - val_loss: 0.2452 - val_acc: 0.9306
Epoch 10/10
60000/60000 [==============================] - 2s - loss: 0.2437 - acc: 0.9300 - val_loss: 0.2335 - val_acc: 0.9339
{"experiment": {"completed": "true"}}
result=$?
+ result=0
echo $result
+ echo 0
0
set +e
+ set +e
echo "{\"studioml\": {\"stop_time\": \"`date '+%FT%T.%N%:z'`\"}}" | jq -c '.'
+ jq -c .
$ 
----

Success !
